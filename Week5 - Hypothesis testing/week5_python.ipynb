{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IntroStat Week 5: Hypothesis Testing\n",
    "\n",
    "Welcome to the 5th lecture in IntroStat\n",
    "\n",
    "During the lectures we will present both slides and notebooks. \n",
    "\n",
    "This is the notebook used in the lecture in week 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.085789Z",
     "start_time": "2024-12-08T16:08:22.701698Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation: Sample from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.089564Z",
     "start_time": "2024-12-08T16:08:25.086795Z"
    }
   },
   "source": [
    "np.random.seed(24) # Seed for reproducibility"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.156002Z",
     "start_time": "2024-12-08T16:08:25.089564Z"
    }
   },
   "source": [
    "# (repeat this cell many times to see the randomness)\n",
    "mu = 100\n",
    "sigma = 12\n",
    "n = 10\n",
    "data = stats.norm.rvs(mu, sigma, size=n) # generate the random normal data\n",
    "x = np.arange(70,130,0.1)\n",
    "plt.xlim(70,130)\n",
    "# plot the normal distribution\n",
    "plt.plot(x, .2*np.sqrt(2*np.pi*sigma**2)*stats.norm.pdf(x, loc=mu, scale=sigma), color=\"red\",alpha=0.3) \n",
    "plt.plot(x, .2*np.sqrt(2*np.pi*sigma**2/n)*stats.norm.pdf(x, loc=mu, scale=sigma/np.sqrt(n)), color=\"black\", linestyle='--',alpha=0.3)\n",
    "# Histogram\n",
    "plt.hist(data, density=True, color='deepskyblue', bins=6)\n",
    "plt.axvline(data.mean(), linestyle='-', color=\"blue\", ymin=0, ymax=1) # Mean\n",
    "plt.plot([data.mean()-data.std(ddof=1)/np.sqrt(n), data.mean()+data.std(ddof=1)/np.sqrt(n)], [0.25/2,0.25/2], linestyle='-', color=\"blue\")\n",
    "# Confidence interval\n",
    "plt.axvline(stats.t.ppf(0.025, df=n-1)*data.std(ddof=1)/np.sqrt(n)+data.mean(), linestyle='--', color=\"blue\", ymin=0, ymax=1)\n",
    "plt.axvline(stats.t.ppf(0.975, df=n-1)*data.std(ddof=1)/np.sqrt(n)+data.mean(), linestyle='--', color=\"blue\", ymin=0, ymax=1)\n",
    "plt.tick_params(left = False, right = False , labelleft = False) \n",
    "plt.show()"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation: ECDF and Q-Q plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Quantile-Quantile (Q-Q) plot step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through the process of creating a Quantile-Quantile (Q-Q) plot step-by-step using the given student height data:\n",
    "\n",
    "**Student Height Data**:\n",
    "`x = [168, 161, 167, 179, 184, 166, 198, 187, 191, 179]`\n",
    "\n",
    "**Goal**:\n",
    "To manually create a Q-Q plot to understand if the data is normally distributed. Q-Q plots compare the quantiles of the given data (`x`) with the quantiles of a standard normal distribution.\n",
    "\n",
    "## Step-by-Step Guide for Creating a Q-Q Plot\n",
    "\n",
    "### Step 1: Organize the Data\n",
    "First, you need to organize and sort your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.159563Z",
     "start_time": "2024-12-08T16:08:25.157007Z"
    }
   },
   "source": [
    "#### Given data\n",
    "x = [168, 161, 167, 179, 184, 166, 198, 187, 191, 179]\n",
    "\n",
    "#### Sort the data in ascending order\n",
    "x_sorted = sorted(x)\n",
    "\n",
    "#### Print sorted data\n",
    "print(x_sorted)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Rank the Data and Calculate Probabilities\n",
    "Calculate the empirical cumulative distribution function (ECDF) quantiles. Since there are 10 values, we'll calculate each value's rank and the corresponding probabilities:\n",
    "\n",
    "- $i $ is the rank (starting from 1 to $n $), where $n = 10 $ is the number of observations.\n",
    "- The empirical probability for each value is calculated as:\n",
    "\n",
    "  $\n",
    "  p_i = \\frac{i - 0.5}{n}\n",
    " $\n",
    "\n",
    "  So the probabilities for our sorted data are:\n",
    "\n",
    "  - $p_1 = \\frac{1 - 0.5}{10} = 0.05 $\n",
    "  - $p_2 = \\frac{2 - 0.5}{10} = 0.15 $\n",
    "  - $p_3 = \\frac{3 - 0.5}{10} = 0.25 $\n",
    "  - $p_4 = \\frac{4 - 0.5}{10} = 0.35 $\n",
    "  - $p_5 = \\frac{5 - 0.5}{10} = 0.45 $\n",
    "  - $p_6 = \\frac{6 - 0.5}{10} = 0.55 $\n",
    "  - $p_7 = \\frac{7 - 0.5}{10} = 0.65 $\n",
    "  - $p_8 = \\frac{8 - 0.5}{10} = 0.75 $\n",
    "  - $p_9 = \\frac{9 - 0.5}{10} = 0.85 $\n",
    "  - $p_{10} = \\frac{10 - 0.5}{10} = 0.95 $\n",
    "\n",
    "#### Step 3: Find Theoretical Quantiles\n",
    "Next, find the theoretical quantiles for a standard normal distribution corresponding to the calculated probabilities. These quantiles are called the \"theoretical quantiles\".\n",
    "\n",
    "You can use the inverse of the cumulative distribution function (CDF), also known as the quantile function, to find these values. In the context of the standard normal distribution, this is often done using the Z-table or a Python function like `scipy.stats.norm.ppf()`:\n",
    "\n",
    "- Theoretical Quantiles ($q_i $) = $\\Phi^{-1}(p_i) $\n",
    "\n",
    "For example:\n",
    "\n",
    "- $q_1 = \\Phi^{-1}(0.05) \\approx -1.645 $\n",
    "- $q_2 = \\Phi^{-1}(0.15) \\approx -1.036 $\n",
    "- $q_3 = \\Phi^{-1}(0.25) \\approx -0.674 $\n",
    "- $q_4 = \\Phi^{-1}(0.35) \\approx -0.385 $\n",
    "- $q_5 = \\Phi^{-1}(0.45) \\approx -0.126 $\n",
    "- $q_6 = \\Phi^{-1}(0.55) \\approx 0.126 $\n",
    "- $q_7 = \\Phi^{-1}(0.65) \\approx 0.385 $\n",
    "- $q_8 = \\Phi^{-1}(0.75) \\approx 0.674 $\n",
    "- $q_9 = \\Phi^{-1}(0.85) \\approx 1.036 $\n",
    "- $q_{10} = \\Phi^{-1}(0.95) \\approx 1.645 $\n",
    "\n",
    "#### Step 4: Plot the Data\n",
    "Now that you have the sorted data values (`x_sorted`) and the corresponding theoretical quantiles (`q_i`), you can create the Q-Q plot:\n",
    "\n",
    "- **X-axis**: Theoretical quantiles ($q_i $) of the normal distribution.\n",
    "- **Y-axis**: Sorted sample quantiles (`x_sorted`).\n",
    "\n",
    "#### Step 5: Draw the Q-Q Line\n",
    "Draw a line that represents the theoretical relationship between the data and the normal distribution. This line should pass through the mean of the data and have a slope equal to the ratio of the standard deviation of the data and the standard deviation of the theoretical quantiles (which is 1 for a standard normal distribution).\n",
    "\n",
    "In Python, you can use scipy.stats.probplot() to create the Q-Q plot and plot the Q-Q line:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.223008Z",
     "start_time": "2024-12-08T16:08:25.159563Z"
    }
   },
   "source": [
    "# In Python, you can use scipy.stats.probplot() to create the Q-Q plot and plot the Q-Q line:\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data\n",
    "x = np.array([168, 161, 167, 179, 184, 166, 198, 187, 191, 179])\n",
    "x_sorted = sorted(x)\n",
    "\n",
    "# Standardize the data (optional step)\n",
    "x_standardized = (x_sorted - np.mean(x)) / np.std(x)\n",
    "\n",
    "print(\"Height data: \", x_sorted)\n",
    "print (\"Z-score of each of the height data:\", x_standardized)\n",
    "\n",
    "# Plotting the Q-Q plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "stats.probplot(x, dist=\"norm\", plot=ax)\n",
    "\n",
    "#probplot() returns osm and osr: Ordered sample and theoretical quantiles.When plot=ax is provided, it generates a Q-Q plot using matplotlib\n",
    "\n",
    "plt.xlabel(\"Theoretical Quantiles\")\n",
    "plt.ylabel(\"Sample Quantiles\")\n",
    "plt.title(\"Q-Q Plot of Student Heights\")\n",
    "plt.show()"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest observations in a Q-Q plot before conducting a hypothesis test using a small dataset are:\n",
    "\n",
    "1. **Linearity of Points**: Check if the points fall approximately along a straight line. This indicates that the data is consistent with the theoretical distribution (e.g., normal).\n",
    "\n",
    "2. **Systematic Deviations**: Look for any systematic patterns, such as curves or S-shapes, which suggest the presence of skewness in the data.\n",
    "\n",
    "3. **Ends of the Plot**: Observe if the points at the ends deviate significantly from the line, indicating heavy tails or kurtosis (extreme values more frequent than expected).\n",
    "\n",
    "4. **Outliers**: Identify any points that fall far away from the reference line, which could be potential outliers in the dataset.\n",
    "\n",
    "These basic observations help determine if the data distribution is approximately normal or has deviations that should be considered before performing hypothesis testing.\n",
    "\n",
    "### Summary\n",
    "1. **Sort the data**.\n",
    "2. **Calculate the empirical probabilities**.\n",
    "3. **Find theoretical quantiles** using the normal distribution's quantile function.\n",
    "4. **Plot the data quantiles vs. the theoretical quantiles**.\n",
    "5. **Check the Q-Q line** to see if the data is approximately normally distributed.\n",
    "\n",
    "This manual process helps in understanding each step involved in constructing a Q-Q plot, giving you insights into the distribution of your data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.225878Z",
     "start_time": "2024-12-08T16:08:25.223008Z"
    }
   },
   "source": [
    "np.random.seed(24)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.274514Z",
     "start_time": "2024-12-08T16:08:25.225878Z"
    }
   },
   "source": [
    "# (repeat this cell many times)\n",
    "data = stats.norm.rvs(mu, sigma, size=n) # Again, generate the random normal data\n",
    "plt.ecdf(data)\n",
    "plt.plot(np.arange(70,130,1), stats.norm.cdf(np.arange(70,130,1), loc=mu, scale=sigma))\n",
    "plt.show()\n",
    "# It should roughly follow the \"perfect\" normal distribution"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.277647Z",
     "start_time": "2024-12-08T16:08:25.274514Z"
    }
   },
   "source": [
    "np.random.seed(24)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.572658Z",
     "start_time": "2024-12-08T16:08:25.277647Z"
    }
   },
   "source": [
    "# import statsmodels.api to do automated q-q-plot\n",
    "import statsmodels.api as sm"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.573663Z",
     "start_time": "2024-12-08T16:08:25.573663Z"
    }
   },
   "source": [
    "# (repeat this cell many times). Sometimes it does not look great, because of the small sample size combined with randomness!\n",
    "data = stats.norm.rvs(mu, sigma, size=n)\n",
    "sm.qqplot(data,line=\"q\",a=3/8) \n",
    "# OBS: \"a = 3/8\" is preferred for n <= 10 \n",
    "#     (\"a = 1/2\" is preferred for n >  10)  \n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try larger samples:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:08:25.574665Z",
     "start_time": "2024-12-08T16:08:25.574665Z"
    }
   },
   "source": [
    "# (repeat this cell many times - then increase n and repeat again)\n",
    "n=10 # also try n = 100\n",
    "data = stats.norm.rvs(mu, sigma, size=n)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10,4))\n",
    "axs[0].hist(data, density=True) # plot 1) - histogram\n",
    "axs[1].ecdf(data) # plot 2) - Empirical CDF\n",
    "axs[1].plot(np.arange(70,130,1), stats.norm.cdf(np.arange(70,130,1), loc=mu, scale=sigma))\n",
    "sm.qqplot(data,line=\"q\",a=1/2,ax=axs[2]) # plot 3) - Q-Q plot\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# examples with exponentially distributed data:\n",
    "\n",
    "n=10 # also try n = 100\n",
    "data = stats.expon.rvs(mu, sigma, size=n) # Not normal random data anymore\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10,4))\n",
    "axs[0].hist(data, density=True)\n",
    "axs[1].ecdf(data)\n",
    "axs[1].plot(np.arange(70,150,1), stats.norm.cdf(np.arange(70,150,1), loc=stats.expon.mean(loc=mu, scale=sigma), scale=stats.expon.std(loc=mu, scale=sigma)))\n",
    "axs[1].set_xlim(70,150)\n",
    "sm.qqplot(data,line=\"q\",a=1/2,ax=axs[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# examples with uniformly distributed data:\n",
    "\n",
    "n=10 # also try n = 100\n",
    "data = stats.uniform.rvs(mu, sigma, size=n)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10,4))\n",
    "axs[0].hist(data, density=True)\n",
    "axs[1].ecdf(data)\n",
    "axs[1].plot(np.arange(90,120,1), stats.norm.cdf(np.arange(90,120,1), loc=stats.uniform.mean(loc=mu, scale=sigma), scale=stats.uniform.std(loc=mu, scale=sigma)))\n",
    "axs[1].set_xlim(90,120)\n",
    "sm.qqplot(data,line=\"q\",a=1/2,ax=axs[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Voltage drop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Enter data\n",
    "x = np.array([0.75,-0.85,4.23,2.12,3.04,0.53,-0.35,1.69,1.52,-0.42])\n",
    "n = len(x)\n",
    "print(x)\n",
    "print(n)\n",
    "# Histogram\n",
    "plt.hist(x)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compute best estimate for the mean (and the standard error)\n",
    "mean_hat = x.mean()\n",
    "se_mean = x.std(ddof=1)/np.sqrt(n)\n",
    "print([mean_hat, x.std(ddof=1), se_mean])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# confidence interval for the mean: (manually)\n",
    "mu_lower = mean_hat - stats.t.ppf(0.975, df=9)*se_mean\n",
    "mu_upper = mean_hat + stats.t.ppf(0.975, df=9)*se_mean\n",
    "print([mu_lower, mu_upper])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the null hypothesis\n",
    "mean_null_hyp = 0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compute the \"test statistic\" from the oberserved data\n",
    "tobs = (mean_hat - mean_null_hyp) / se_mean\n",
    "print(tobs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# compare with t_0.975 from t-distribution with df = 9\n",
    "t_criticial = stats.t.ppf(0.975, df=n-1)\n",
    "print(t_criticial)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "p_value= 2*stats.t.cdf(-tobs, df=n-1)\n",
    "print(p_value)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# You can also use the ttest_1samp funtion from scipy.stats:\n",
    "print(stats.ttest_1samp(x, popmean=0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Difference in calorie-intake"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot histogram of data\n",
    "x = np.array([1350, 1250, 1755, 1020, 745, 1835, 1540, 1540, 725, 1330, 1435])\n",
    "plt.hist(x, density=True)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does the data actually follow a normal distribution? <br>\n",
    "\n",
    "How well can we expect 11 obervations to \"look\" like a normal distribution?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# calculate mean and SEM (Standard Error of the Mean)\n",
    "xbar = x.mean()\n",
    "n = 11\n",
    "SEM = x.std(ddof=1)/np.sqrt(n)\n",
    "print(xbar, SEM)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# calculate t_obs\n",
    "t_obs = (xbar-0)/SEM\n",
    "print(t_obs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already now see that t_obs is very large"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# calculate p-value\n",
    "pval = 2*stats.t.cdf(-t_obs,df=n-1)\n",
    "print(pval)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is smaller than 0.05 (and also smaller than 0.001).\n",
    "So we reject the nulhypothesis "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# we could also calculate the 95% conficence interval for the mean\n",
    "mu_lower = xbar - stats.t.ppf(0.975,df=n-1)*SEM\n",
    "mu_upper = xbar + stats.t.ppf(0.975,df=n-1)*SEM\n",
    "print([mu_lower, mu_upper])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the confidence interval does not include the value 0"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# You can also use the ttest_1samp funtion from scipy.stats:\n",
    "print(stats.ttest_1samp(x, popmean=0))"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pernille",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
